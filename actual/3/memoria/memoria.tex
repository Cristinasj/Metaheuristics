\documentclass[12pt, spanish]{article}
\newcommand\tab[1][1cm]{\hspace*{#1}}
\usepackage[spanish]{babel}
\selectlanguage{spanish}
\usepackage{natbib}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{vmargin}
\usepackage{multirow}
\usepackage{float}
\usepackage{chngpage}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{subcaption}

\usepackage{hyperref}
\usepackage[
    type={CC},
    modifier={by-nc-sa},
    version={4.0},
]{doclicense}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

% para codigo
\usepackage{listings}
\usepackage{xcolor}



%% configuración de listings

\definecolor{listing-background}{HTML}{F7F7F7}
\definecolor{listing-rule}{HTML}{B3B2B3}
\definecolor{listing-numbers}{HTML}{B3B2B3}
\definecolor{listing-text-color}{HTML}{000000}
\definecolor{listing-keyword}{HTML}{435489}
\definecolor{listing-identifier}{HTML}{435489}
\definecolor{listing-string}{HTML}{00999A}
\definecolor{listing-comment}{HTML}{8E8E8E}
\definecolor{listing-javadoc-comment}{HTML}{006CA9}

\lstdefinestyle{eisvogel_listing_style}{
  language         = c++,
%$if(listings-disable-line-numbers)$
%  xleftmargin      = 0.6em,
%  framexleftmargin = 0.4em,
%$else$
  numbers          = left,
  xleftmargin      = 0em,
 framexleftmargin = 0em,
%$endif$
  backgroundcolor  = \color{listing-background},
  basicstyle       = \color{listing-text-color}\small\ttfamily{}\linespread{1.15}, % print whole listing small
  breaklines       = true,
  frame            = single,
  framesep         = 0.19em,
  rulecolor        = \color{listing-rule},
  frameround       = ffff,
  tabsize          = 4,
  numberstyle      = \color{listing-numbers},
  aboveskip        = 1.0em,
  belowskip        = 0.1em,
  abovecaptionskip = 0em,
  belowcaptionskip = 1.0em,
  keywordstyle     = \color{listing-keyword}\bfseries,
  classoffset      = 0,
  sensitive        = true,
  identifierstyle  = \color{listing-identifier},
  commentstyle     = \color{listing-comment},
  morecomment      = [s][\color{listing-javadoc-comment}]{/**}{*/},
  stringstyle      = \color{listing-string},
  showstringspaces = false,
  escapeinside     = {/*@}{@*/}, % Allow LaTeX inside these special comments
  literate         =
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\'e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
  {…}{{\ldots}}1 {≥}{{>=}}1 {≤}{{<=}}1 {„}{{\glqq}}1 {“}{{\grqq}}1
  {”}{{''}}1
}
\lstset{style=eisvogel_listing_style}


\usepackage[default]{sourcesanspro}

\setmarginsrb{2 cm}{1 cm}{2 cm}{2 cm}{1 cm}{1.5 cm}{1 cm}{1.5 cm}

\title{Práctica 3:\\
APC - Búsquedas por Trayectorias  \hspace{0.05cm} }                           
\author{Cristina Sánchez Justicia}                             
\date{\today}                                           

\renewcommand*\contentsname{hola}

\makeatletter
\let\thetitle\@title
\let\theauthor\@author
\let\thedate\@date
\makeatother

\pagestyle{fancy}
\fancyhf{}
\rhead{\theauthor}
\lhead{\thetitle}
\cfoot{\thepage}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
    \centering
    \vspace*{0.3 cm}
    \includegraphics[scale = 0.50]{ugr.png}\\[0.7 cm]
    %\textsc{\LARGE Universidad de Granada}\\[2.0 cm]   
    \textsc{\large 3º CSI 2022/23 - Grupo 1}\\[0.5 cm]                \textsc{\large Grado en Ingeniería Informática}\\[0.5 cm]              
    \rule{\linewidth}{0.2 mm} \\[0.2 cm]
    { \huge \bfseries \thetitle}\\
	Algoritmos: 
	1-NN, RELIEF, BL, AGE-BLX, AGE-CA, BMB, ES, ILS, ILS-ES, VNS \\
    \rule{\linewidth}{0.2 mm} \\[1 cm]
    
    \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \large
            \emph{Autor:}\\
            \theauthor\\ 
			 \emph{DNI:}\\
            77689772G
            \end{flushleft}
            \end{minipage}~
            \begin{minipage}{0.4\textwidth}
            \begin{flushright} \large
            \emph{Asignatura: \\
            Metaheurísticas}   \\     
            \emph{Correo:}\\
            cristina@correo.ugr.es           
        \end{flushright}
    \end{minipage}\\[0.5cm]
  
    {\large \thedate}\\[0.5cm]
    {\url{https://github.com/cristinasj/MH/}}
 	
    \vfill
    
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Descripción del problema}
Los problemas de clasificación son un clásico de la Inteligencia Artificial y, más específicamente, el Aprendizaje Automático. Los elementos con los que se trabajan en un problema de clasificación son un conjunto de datos, que pueden ser imágenes, audios, textos… Los cuales son fáciles de distinguir por un humano. Por ejemplo, un humano podría distinguir entre una imagen de un árbol y una imagen de una flor. El objetivo es conseguir de cualquier forma que un ordenador pueda clasificar de la misma forma, si no mejor, que un humano.  \\ \\
El Aprendizaje de Pesos en Características es una variación del problema de clasificación en el que en nuestro conjunto de datos, por cada elemento tenemos un vector de características que lo definen. Este problema se puede solucionar de muchas maneras pero en esta práctica nosotros utilizaremos el claisificador K-NN, la Busqueda Local y el método RELIEF.  
\pagebreak

\section{Descripción de la aplicación de los algoritmos aplicados al problema }

Las consideraciones comunes a los distintos algoritmos son las siguientes: 

\subsection{Esquemas de representación}
Al igual que en anteriores prácticas la representación adoptada implica el uso de un vector W de longitud n, donde cada elemento tiene un valor en el rango [0, 1]. Este vector representa el peso asociado a cada característica y determina su capacidad para ser eliminada si su peso es menor que 0.1. \\
\newline 
Para representar esto se utilizan las siguientes estructuras de datos: 
\begin{enumerate}[label=-]
  \item Elemento: en la anterior práctica se utilizó una clase llamada Elemento. En esta práctica los elementos van en una matriz junto con una lista de caracteristicas paralela para ahorrar tiempo de ejecución.
  \item Set de datos: matriz bidimensional numpy donde cada fila representa un vector de caracteristicas y cada columna los valores de una caracteristica 
  \item  Soluciones: arrays de pesos paralelos a los vectores de características de cada elemento. Cada valor del array representa la importancia de cada característica para buscar la distancia mínima ponderada al utilizar el clasificador 1-NN. Sus valores están siempre entre 0 y 1. 
\end{enumerate}
\subsection{Descripción de la función objetivo }
La función objetivo se llama funciónEvaluacion y se dedica a dar una valoración numérica a unos pesos entrenados con los diferentes algoritmos. Para ello tiene en cuenta el porcentaje de reducción y el porcentaje de clasificación. En nuestro caso damos un 80\% de importancia a la clasificación y un 20\% de importancia a la reducción. \\
\newline
El porcentaje de reducción nos dice cómo de mucho se simplifica el problema con esos pesos. Es decir, a cuanto mayor sea el porcentaje de reducción, menos poder computacional es necesario para generar el resultado de clasificación al utilizar nuestro clasificador en producción, es decir, en un caso real. Este porcentaje de reducción se obtiene calculando el porcentaje de pesos que son cercanos a 0, es decir, el porcentaje de pesos que apenas importan información a la hora de clasificar a un individuo. \\
\newline
El porcentaje de clasificación nos dice el porcentaje de aciertos de nuestro clasificador. Para eso utiliza un conjunto de evaluación y un conjunto de entrenamiento y se ejecuta el clasificador 1-NN sobre cada elemento del conjunto de evaluación y respecto al conjunto de entrenamiento, usando una distancia ponderada dada por los pesos. 

\subsection{Descripción de los operadores comunes}
El operador distancia nos da la distancia cuadrada, euclídea y ponderada de un elemento a otro. La distancia es cuadada para ahorrar calculos y acelerar el proceso ya que no nos interesa el valor real en el cálculo de 1NN. La distancia es euclídea porque todas las variables en esta práctica son continuas. 
El operador distancia está implementado de la siguiente forma: 

function distancia (array\_caracteristicas uno, array\_caracteristicas otro, array\_caracteristicas pesos): \\ 
\tab    if pesos.esNulo( ):\\ 
\tab\tab 	    pesos.llenarDeUnos( )\\
devolver sumatoria((uno-otro)² * pesos)\\

\subsection{Pseudocódigo del proceso de generación de soluciones aleatorias}
La solución inicial se obtendrá de manera aleatoria en todos los casos, utilizando una distribución uniforme en el rango de [0, 1].\\
\newline
Para implementar esto, se utiliza la función rand de la biblioteca numpy y el módulo random como se muestra en este pseudocódigo:\\
\\
para\_cada i en (0, 1, 2, ...,  t\_poblacion):\\
\tab       	pesos = np.random.rand(datos.tamaño())\\
   \tab    	evaluacion = evaluar(datos, pesos) \\
\tab	poblacion.incluir(pesos, evaluacion)\\
end\_para\\

\subsection{Operador de cruce BLX}
Recibe dos cromosomas y genera dos descendientes generados aleatoriamente en un intervalo que depende de los valores de los padres. El pseudocódigo es el siguiente: \\
\\
funcion cruce\_BLX(cromosoma c1 ,cromosoma c2) devuelve una pareja de cromosomas:\\
\tab    para\_cada gen1 y gen2 en c1 y c2 :	\\
\tab\tab	alfa = 0.3\\
\tab\tab	min, max = devolverMinMax(gen1, gen2)\\
\tab\tab    	l = max-min\\
\tab\tab   	b1 = min-l*alfa\\
\tab\tab    	b2 = cmax+l*0.3\\
\tab\tab    devolver np.random.uniform(b1, b2), np.random.uniform(b1, b2)\\

\subsection{Operador de Cruce Aritmético}
Combina los pesos de los dos padres con una media aritmética con alfa aleatório. El pseudocódigo es el siguiente: \\
\\
funcion cruce\_CA(cromosoma c1, cromosoma c2) -> devuelve una pareja de cromosomas: \\
\tab    alpha = generar aleatorio \\
\tab    salida1 = c1*alpha + c2*(1-alpha)\\
\tab   salida2 = c1*(1-alpha) + c2*alpha\\
\tab    return salida1, salida2\\


\subsection{Esquema de generación de vecinos en ES e ILS}
La generación de vecinos en ES es similar a el operador de mutación de la práctica anterior y el operador de exploración de vecinos de la primera práctica. El pseudocódigo es el siguiente: 

funcion mutacion(i, j, poblacion):\\
\tab  poblacion[i][j] += np.random.normal(0, 0.3)\\
\tab  if (poblacion[i][j] < 0): poblacion[i][j] = 0\\
\tab  if (poblacion[i][j] > 1): poblacion[i][j] = 1\\
\\
\\
Para ILS es un poco diferente ya que se muta el vector entero y no solo una posición, y es de esta forma: 
\tab funcion mutar(w):
\tab\tab vector_mutado = w.copy()
 \tab index = [i for i in range(len(w)) if w[i] > 0.4]
  \tab np.random.shuffle(index)
  \tab t = (int)(len(index)*0.1)
  \tab   for i in range(0, t):
 \tab  \tab vector_mutado[i] += np.random.normal(0, 0.3)
   \tab \tab if (vector_mutado[i] < 0):
 \tab \tab \tab vector_mutado[i] = 0
 \tab \tab  if (vector_mutado[i] > 1):
 \tab \tab \tab vector_mutado[i] = 1
  \tab  return vector_mutado

\pagebreak


\section{Descripción de las metaheuristicas}
\subsection{RELIEF }
Se basa en encontrar el elemento más cercano de su misma clase (amigo) y elemento más cercano de diferente clase (enemigo). Para ello se utilizan los métodos amigo() y enemigo() de la clase Elemento. Se recorren todos los elemento y se actualizan los pesos, previamente inicializados a 0, sumando la distancia del enemigo y restando la distancia al amigo. Posteriormente se normaliza el valor al rango [0,1]. \\
\\
funcion relief(conjunto\_entrenamiento) {\\
\tab	pesos = Array.zeros(conjunto\_entrenamiento.longitudes)\\
\tab	loop i in entrenamiento {\\
\tab\tab		amigo = conjunto\_entrenamiento[i].amigo() \\
\tab\tab		enemigo = conjunto\_entrenamiento[i].enemigo() \\
\tab		pesos.actualizar(amigo, enemigo) \\
	}\\
\tab	pesos.normalizar() \\
\tab	devolver pesos\\
}\\

\pagebreak
\subsection{BL}
Para definir una busqueda local necesitamos generación de soluciones aleatorias, un operador de generación de vecinos y método de exploración del entorno. Queda aclarar que en la solución implementada no se genera el vecindario entero antes de realizar la búsqueda, sino se van generando vecinos de forma aleatoria hasta encontrar una mejoría. En el código fuente estas funciones no han sido implementadas por separado, sino todas juntas en en la función BL. \\
\\
funcion soluciones\_aleatorias(min=0, max=1, tamaño\_vector) { \\
\tab	devolver Aleatorio(min, max, tamaño\_vector) \\
}\\
funcion generacion\_vecino(pesos\_inciales, desviacion\_standard, media, posicion) {\\
\tab	devolver pesos\_inciales[posicion].variar(media, desviacion\_standard).truncar()\\
}\\
funcion exploracion\_entorno(conjunto\_entrenamiento) {\\
\tab	pesos\_actuales = soluciones\_aleatorias(0,1,conjunto\_entrenamiento.longitudes)\\
\tab	evaluacion\_actual = evaluarLeave1out(conjunto\_entrenamiento, pesos\_actuales)\\
\tab	loop mientras mejorable y no\_lleva\_mucho\_ejecutando{\\
\tab		vecino = generacion\_vecino(pesos\_actuales, 0.2, 0, Permutacion)\\
\tab		evaluacion\_vecino = evaluarLeave1out(conjunto\_entrenamiento, vecino) \\
\tab		if evaluacion\_vecino > evaluacion\_actual {\\
\tab\tab			evaluacion\_actual = evaluacion\_vecino\\
	\tab\tab		pesos\_actuales  = vecino \\
		}\\
	}	 \\
} \\
\subsection{Algoritmos genéticos estacionarios}
funcion estacionario(Poblacion matriz\_datos, funcion tipo\_cruce) devuelve un array de pesos:\\
 \tab  \\\ Se ordena la población\\
 \tab  poblacion = ordenar(matriz\_datos, funcion\_evaluacion) \\
\tab	 repetir 15000 veces:\\
   \tab\tab    \\\ Competición entre 4 individuos\\
  \tab \tab   seleccion = poblacion.elegir4individuos()\\
   \tab    c1, c2 = torneoTetra(seleccion)\\
\\
   \tab    \\\ Se hacen los cruces\\
      \tab h1, h2 = tipo\_cruce(c1, c2)\\
\\
     \tab  \\\ Se aplican las mutaciones\\
   \tab    mutar(seleccion\_aleatoria(poblacion))\\
    \tab   h1.evaluacion = evaluar(h1)\\
      \tab h2.evaluacion = evaluar(h2) \\
\\
\tab        \\\ Competición para entrar en la poblacion\\
   \tab    seleccion[0] = h1\\
   \tab    seleccion[1] = h2\\
    \tab   seleccion[2] = poblacion[0]\\
      \tab seleccion[3] = poblacion[1]\\
     \tab  seleccion.ordenar()\\
     \tab  poblacion[0] = seleccion.mejor()\\
     \tab  poblacion[1] = seleccion.segundo\_mejor() \\
     \tab  poblacion.ordenar() \\
\\
\tab    devolver poblacion.mejor\_cromosoma()\\
\pagebreak
\subsection{Enfriamiento simulado}
\subsubsection{Esquema de enfiamiento}
Se va a utilizar el esquema de Cauchy. Este es una forma de ajustar la temperatura en el algoritmo de enfriamiento simulado. En el esquema de Cauchy, la temperatura se reduce de acuerdo con una función específica conocida como función de enfriamiento de Cauchy.\\
\\
La función de enfriamiento de Cauchy se define de la siguiente manera:\\

    \[ T_{k+1} = \frac{k}{1 + T_k} \]
\\
Sin embargo, en la práctica se va a utilizar este esquema modificado. Se va a utilizar \(\beta\) en lugar de \(k\), de la siguiente manera:

\[ T_{k+1} = \frac{T_k}{1 + \beta*T_{k}} \]

donde:\\
- \( T_{\beta+1} \) es la temperatura en la iteración \( \beta+1 \),\\
- \( T_0 \) es la temperatura inicial,\\
- \( T_f \) es la temperatura final,\\
- \( M \) es un factor de ajuste, y\\
- \( \beta \) es el parámetro de enfriamiento.\\
\\
Para calcular el valor de \( \beta \) se utiliza la fórmula:
\[ \beta = \frac{T_0 - T_f}{M \cdot T_0 \cdot T} \]

A medida que \( \beta \) aumenta, el denominador \( 1 + \beta \) se vuelve más grande, lo que reduce la temperatura de manera efectiva.

\\
\subsubsection{Operador de vecino}
Para el operador de vecino se utiliza la función de mutación anteriormente descrita.
\subsubsection{Condición de enfriamiento}

\subsubsection{Condición de parada}
\pagebreak
\subsection{Búsqueda Multiarranque Básica}
La Heurística de Búsqueda Multiarranque Básica (Basic Multi-Start Search en inglés) es una técnica de optimización utilizada para resolver problemas de optimización combinatoria. Esta heurística se basa en la idea de realizar múltiples arranques aleatorios del algoritmo de búsqueda local y combinar los resultados obtenidos para encontrar una solución óptima.

La implementación sigue el siguiente esquema: 

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon
Input: entrenamiento, etiquetas\\
Output: wMejor\\
\\
numArranques = 15;\\
wIni = generarVectorAleatorio(len(entrenamiento[0]));\\
wMejor = BL(entrenamiento, etiquetas, wIni);\\
fMejor = funcionEvaluacionLeaveOneOut(entrenamiento, etiquetas, wMejor);\\
\For{i $\leftarrow$ 1 \KwTo numArranques}{\\
\tab w = BL(entrenamiento, etiquetas, generarVectorAleatorio(len(entrenamiento[0])));\\
\tab f = funcionEvaluacionLeaveOneOut(entrenamiento, etiquetas, w);\\
\tab \If{f > fMejor}{\\
\tab \tab fMejor = f;\\
\tab \tab wMejor = copiarVector(w);\\
}\\
}\\
\Return wMejor;\\
\caption{Búsqueda Multiarranque Básica (BMB)}
\end{algorithm}

\pagebreak
\subsection{Búsqueda Local Reiterada (ILS)}
 
\pagebreak
\subsection{Variable Neighborhood Search}
\pagebreak
\subsection{ILS-ES}
\pagebreak

\section{Descripción en pseudocódigo de los algoritmos de comparación}

\pagebreak

\section{Procedimiento considerado para desarrollar la práctica}
Para esta práctica se ha decidido utilizar el lenguaje de programación Python por la velocidad de desarrollo y claridad del código. También se ha utilizado la librería numpy para la optimización de los calculos de los arrays. Como generación de numeros aleatorios se ha confiado en el módulo numpy.random y para medir el tiempo, la biblioteca time.  
\pagebreak
\subsection{Manual del usuario}
- Requisitos: Python3 y las librerías numpy, functools, arff, time \\
- Abrir el directorio donde se encuentra el archivo main.py en una terminal\\ 
- Ejecutar python3 main.py\\ 
- Esperar alrededor de 1 hora. Como indicación de progreso se puede leer de la salida standard los algoritmos ejecutados hasta el momento así como el que se está ejecutando actualmente. Hay 2 algoritmos, 3 bases de datos diferentes y 5 particiones de las bases de datos, por lo tanto hay 30 subapartados que deben ejecutarse en total.\\ 
- Los resultados pueden leerse de la salida standard así como del fichero resultados.csv\\
\subsection{Mejoras realizadas respecto a las prácticas anteriores}
La retroalimentación de la primera práctica ha sido muy útil para mejorar la presentación de esta segunda práctica. Las mejoras adoptadas han sido las siguientes:\\
\subsubsection{Ejecución modular}
En las anteriores entregas se presentaba un código que ejecutaba los algoritmos uno tras otro y generaba automáticamente las tablas a entregar. Para esta práctica se ha adaptado el programa para poder especificar como parámetro el algoritmo a ejecutar. Esta nueva implementación tiene muchas ventajas. \\
Por una parte, permite una simulación de ejecución multihebra sin requerir bibliotecas adicionales. Esto reduce el tiempo para aprender nuevas bibliotecas ya que tiene una curva de aprendizaje muy suave. Además, la depuración es muy sencilla  \\
Por otra parte, también permite un desarrollo modular de la práctica, de forma que se puede implementar y ejecutar algoritmos por separado y hacer un avance incremental de la práctica. Gracias a esto los algoritmos más lentos pueden utilizar todas las horas que necesiten mientras se documentan los resultados de los algoritmos que ya hayan terminado su ejecución. \\ 
\subsubsection{Instrucciones de uso en el programa}
Se ha creado un menú para facilitar al usuario introducir los datos correctos. 
\subsubsection{Mejora de la presentación de la documentación}
La memoria en las entregas anteriores estaba escrita en un procesador de textos. Para mejorar la presentación de la memoria se ha decidido cambiar a LaTeX. De esta forma se pueden incluir fórmulas, índice generado automáticamente, imagenes incrustadas de manera más profesional y mayor homogeneidad en el pseudocódigo, además de ser más fácil de reconocer entre el resto del texto. \\

\pagebreak

\section{Experimentos y análisis de los resultados}
\subsection{Casos del problema empleados y valores de los parámetros considerados}
Incluir semillas utilizzdas
Dado el tiempo necesario para ejecutar el programa (alrededor de 20 minutos), los pesos solo se han entrenado una vez con cada algoritmo y base de datos diferente, utilizando la semilla por defecto de la libería time. 

\subsection{Tablas de resultados obtenidos}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{tables1.png}
  \caption{Descripción de la imagen.}
  \label{fig:imagen}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{tables2.png}
  \caption{Descripción de la imagen.}
  \label{fig:imagen}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{tables3.png}
  \caption{Descripción de la imagen.}
  \label{fig:imagen}
\end{figure}


\pagebreak
\subsection{Análisis de resultados}
gráficas de convergencia, boxplots, análisis comparativo de las soluciones obtenidas, representación gráfica de las soluciones
\subsubsection{1-NN}
Este es el algoritmo base que hay que mejorar así que como era de esperar tiene las tasas de clasificación y reducción más bajas, aún así el tiempo de ejecución es casi despreciable. El porcentaje de clasificación es soprendentemente mejor para Spect-heart.
\subsubsection{Busqueda Local}
El porcentaje de clasificación tanto como el de reducción son los mejores en la mayor parte de los casos, descartando en Ozone, donde la reducción de RELIEF es mejor. 

\subsubsection{RELIEF}
Los resultados tienden a ser mejores que 1-NN pero inferiores a BL. En algunos casos puede presentar los mejores resultados, como en el porcentaje de clasificación de Ozone o el porcentaje de reducción de Spect-heart. El tiempo requerido también es varios ordenes de magnitud inferior al requerido por BL. 
\subsubsection{AGE-BLX}
El porcentaje de reducción, así como el porcentaje de clasificación son notablemente mejores que los de los algoritmos de la práctica anterior. Sin embargo, el tiempo en los algoritmos genéticos también avanza mucho. 
\subsubsection{AGE-CA}
El porcentaje de reducción es preocupantemente bajo en comparación con el algoritmo que utiliza BLX. Cabe preguntarse si eso es debido a algún error en la implementación del operador de cruce. El tiempo de ejecución también es muy alto en comparación a los algoritmos anteriores. 
\subsubsection{}
\subsubsection{}
\subsubsection{}
\subsubsection{}
\subsubsection{}
\subsubsection{Conclusión}
En la anterior práctica se concluía que no merecía la pena el tiempo de ejecución de BL y RELIEF, así como la complejidad de implementación, cuando utilizar unos pesos no ponderados no presenta unos resultados mucho peores. Sin embargo, en esta práctica se puede apreciar que la mejora en reducción y clasificación es muy buena en los algoritmos genéticos. 
\pagebreak
\section{Referencias bibliográficas}
\end{document}