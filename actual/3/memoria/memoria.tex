\documentclass[12pt, spanish]{article}
\usepackage[spanish]{babel}
\selectlanguage{spanish}
\usepackage{natbib}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{vmargin}
\usepackage{multirow}
\usepackage{float}
\usepackage{chngpage}
\usepackage{enumitem}

\usepackage{subcaption}

\usepackage{hyperref}
\usepackage[
    type={CC},
    modifier={by-nc-sa},
    version={4.0},
]{doclicense}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

% para codigo
\usepackage{listings}
\usepackage{xcolor}



%% configuración de listings

\definecolor{listing-background}{HTML}{F7F7F7}
\definecolor{listing-rule}{HTML}{B3B2B3}
\definecolor{listing-numbers}{HTML}{B3B2B3}
\definecolor{listing-text-color}{HTML}{000000}
\definecolor{listing-keyword}{HTML}{435489}
\definecolor{listing-identifier}{HTML}{435489}
\definecolor{listing-string}{HTML}{00999A}
\definecolor{listing-comment}{HTML}{8E8E8E}
\definecolor{listing-javadoc-comment}{HTML}{006CA9}

\lstdefinestyle{eisvogel_listing_style}{
  language         = c++,
%$if(listings-disable-line-numbers)$
%  xleftmargin      = 0.6em,
%  framexleftmargin = 0.4em,
%$else$
  numbers          = left,
  xleftmargin      = 0em,
 framexleftmargin = 0em,
%$endif$
  backgroundcolor  = \color{listing-background},
  basicstyle       = \color{listing-text-color}\small\ttfamily{}\linespread{1.15}, % print whole listing small
  breaklines       = true,
  frame            = single,
  framesep         = 0.19em,
  rulecolor        = \color{listing-rule},
  frameround       = ffff,
  tabsize          = 4,
  numberstyle      = \color{listing-numbers},
  aboveskip        = 1.0em,
  belowskip        = 0.1em,
  abovecaptionskip = 0em,
  belowcaptionskip = 1.0em,
  keywordstyle     = \color{listing-keyword}\bfseries,
  classoffset      = 0,
  sensitive        = true,
  identifierstyle  = \color{listing-identifier},
  commentstyle     = \color{listing-comment},
  morecomment      = [s][\color{listing-javadoc-comment}]{/**}{*/},
  stringstyle      = \color{listing-string},
  showstringspaces = false,
  escapeinside     = {/*@}{@*/}, % Allow LaTeX inside these special comments
  literate         =
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\'e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
  {…}{{\ldots}}1 {≥}{{>=}}1 {≤}{{<=}}1 {„}{{\glqq}}1 {“}{{\grqq}}1
  {”}{{''}}1
}
\lstset{style=eisvogel_listing_style}


\usepackage[default]{sourcesanspro}

\setmarginsrb{2 cm}{1 cm}{2 cm}{2 cm}{1 cm}{1.5 cm}{1 cm}{1.5 cm}

\title{Práctica 3:\\
APC - Búsquedas por Trayectorias  \hspace{0.05cm} }                           
\author{Cristina Sánchez Justicia}                             
\date{\today}                                           

\renewcommand*\contentsname{hola}

\makeatletter
\let\thetitle\@title
\let\theauthor\@author
\let\thedate\@date
\makeatother

\pagestyle{fancy}
\fancyhf{}
\rhead{\theauthor}
\lhead{\thetitle}
\cfoot{\thepage}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
    \centering
    \vspace*{0.3 cm}
    \includegraphics[scale = 0.50]{ugr.png}\\[0.7 cm]
    %\textsc{\LARGE Universidad de Granada}\\[2.0 cm]   
    \textsc{\large 3º CSI 2022/23 - Grupo 1}\\[0.5 cm]                \textsc{\large Grado en Ingeniería Informática}\\[0.5 cm]              
    \rule{\linewidth}{0.2 mm} \\[0.2 cm]
    { \huge \bfseries \thetitle}\\
	Algoritmos: 
	1-NN, RELIEF, BL, AGE-BLX, AGE-CA, BMB, ES, ILS, ILS-ES, VNS \\
    \rule{\linewidth}{0.2 mm} \\[1 cm]
    
    \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \large
            \emph{Autor:}\\
            \theauthor\\ 
			 \emph{DNI:}\\
            77689772G
            \end{flushleft}
            \end{minipage}~
            \begin{minipage}{0.4\textwidth}
            \begin{flushright} \large
            \emph{Asignatura: \\
            Metaheurísticas}   \\     
            \emph{Correo:}\\
            cristina@correo.ugr.es           
        \end{flushright}
    \end{minipage}\\[0.5cm]
  
    {\large \thedate}\\[0.5cm]
    {\url{https://github.com/cristinasj/MH/}}
 	
    \vfill
    
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Descripción del problema}
Los problemas de clasificación son un clásico de la Inteligencia Artificial y, más específicamente, el Aprendizaje Automático. Los elementos con los que se trabajan en un problema de clasificación son un conjunto de datos, que pueden ser imágenes, audios, textos… Los cuales son fáciles de distinguir por un humano. Por ejemplo, un humano podría distinguir entre una imagen de un árbol y una imagen de una flor. El objetivo es conseguir de cualquier forma que un ordenador pueda clasificar de la misma forma, si no mejor, que un humano.  \\ \\
El Aprendizaje de Pesos en Características es una variación del problema de clasificación en el que en nuestro conjunto de datos, por cada elemento tenemos un vector de características que lo definen. Este problema se puede solucionar de muchas maneras pero en esta práctica nosotros utilizaremos el claisificador K-NN, la Busqueda Local y el método RELIEF.  
\pagebreak

\section{Descripción de la aplicación de los algoritmos aplicados al problema }

Las consideraciones comunes a los distintos algoritmos son las siguientes: 

\subsection{Esquemas de representación}
Al igual que en anteriores prácticas la representación adoptada implica el uso de un vector W de longitud n, donde cada elemento tiene un valor en el rango [0, 1]. Este vector representa el peso asociado a cada característica y determina su capacidad para ser eliminada si su peso es menor que 0.1. \\
\newline 
Para representar esto se utilizan las siguientes estructuras de datos: 
\begin{enumerate}[label=-]
  \item Elemento: en la anterior práctica se utilizó una clase llamada Elemento. En esta práctica los elementos van en una matriz junto con una lista de caracteristicas paralela para ahorrar tiempo de ejecución.
  \item Set de datos: matriz bidimensional numpy donde cada fila representa un vector de caracteristicas y cada columna los valores de una caracteristica 
  \item  Soluciones: arrays de pesos paralelos a los vectores de características de cada elemento. Cada valor del array representa la importancia de cada característica para buscar la distancia mínima ponderada al utilizar el clasificador 1-NN. Sus valores están siempre entre 0 y 1. 
\end{enumerate}
\subsection{Descripción de la función objetivo }
La función objetivo se llama funciónEvaluacion y se dedica a dar una valoración numérica a unos pesos entrenados con los diferentes algoritmos. Para ello tiene en cuenta el porcentaje de reducción y el porcentaje de clasificación. En nuestro caso damos un 80\% de importancia a la clasificación y un 20\% de importancia a la reducción. \\
\newline
El porcentaje de reducción nos dice cómo de mucho se simplifica el problema con esos pesos. Es decir, a cuanto mayor sea el porcentaje de reducción, menos poder computacional es necesario para generar el resultado de clasificación al utilizar nuestro clasificador en producción, es decir, en un caso real. Este porcentaje de reducción se obtiene calculando el porcentaje de pesos que son cercanos a 0, es decir, el porcentaje de pesos que apenas importan información a la hora de clasificar a un individuo. \\
\newline
El porcentaje de clasificación nos dice el porcentaje de aciertos de nuestro clasificador. Para eso utiliza un conjunto de evaluación y un conjunto de entrenamiento y se ejecuta el clasificador 1-NN sobre cada elemento del conjunto de evaluación y respecto al conjunto de entrenamiento, usando una distancia ponderada dada por los pesos. 

\subsection{Descripción de los operadores comunes}
El operador distancia nos da la distancia cuadrada, euclídea y ponderada de un elemento a otro. La distancia es cuadada para ahorrar calculos y acelerar el proceso ya que no nos interesa el valor real en el cálculo de 1NN. La distancia es euclídea porque todas las variables en esta práctica son continuas. 
El operador distancia está implementado de la siguiente forma: 

function distancia (array\_caracteristicas uno, array\_caracteristicas otro, array\_caracteristicas pesos):  
    if pesos.esNulo( ): 
	    pesos.llenarDeUnos( )
devolver sumatoria((uno-otro)² * pesos)

\subsection{Pseudocódigo del proceso de generación de soluciones aleatorias}
La solución inicial se obtendrá de manera aleatoria en todos los casos, utilizando una distribución uniforme en el rango de [0, 1].\\
\newline
Para implementar esto, se utiliza la función rand de la biblioteca numpy y el módulo random como se muestra en este pseudocódigo
para\_cada i en (0, 1, 2, ...,  t\_poblacion):
       	pesos = np.random.rand(datos.tamaño())
        	evaluacion = evaluar(datos, pesos) 
	poblacion.incluir(pesos, evaluacion)
end\_para
\subsection{Operador de cruce BLX}
Recibe dos cromosomas y genera dos descendientes generados aleatoriamente en un intervalo que depende de los valores de los padres. El pseudocódigo es el siguiente: 
funcion cruce\_BLX(cromosoma c1 ,cromosoma c2) devuelve una pareja de cromosomas:
    para\_cada gen1 y gen2 en c1 y c2 :	
	alfa = 0.3
	min, max = devolverMinMax(gen1, gen2)
    	l = max-min
    	b1 = min-l*alfa
    	b2 = cmax+l*0.3
    devolver np.random.uniform(b1, b2), np.random.uniform(b1, b2)
\subsection{Operador de Cruce Aritmético}
Combina los pesos de los dos padres con una media aritmética con alfa aleatório. El pseudocódigo es el siguiente: 
funcion cruce\_CA(cromosoma c1, cromosoma c2) -> devuelve una pareja de cromosomas: 
    alpha = generar aleatorio 
    salida1 = c1*alpha + c2*(1-alpha)
    salida2 = c1*(1-alpha) + c2*alpha
    return salida1, salida2
\subsection{Esquema de generación de vecinos en ES e ILS}
La generación de vecinos en ES e ILS es similar a el operador de mutación de la práctica anterior y el operador de exploración de vecinos de la primera práctica. El pseudocódigo es el siguiente: 

funcion mutacion(i, j, poblacion):
  poblacion[i][j] += np.random.normal(0, 0.3)
  if (poblacion[i][j] < 0): poblacion[i][j] = 0
  if (poblacion[i][j] > 1): poblacion[i][j] = 1

\pagebreak


\section{Descripción de las metaheuristicas}
\subsection{RELIEF }
Se basa en encontrar el elemento más cercano de su misma clase (amigo) y elemento más cercano de diferente clase (enemigo). Para ello se utilizan los métodos amigo() y enemigo() de la clase Elemento. Se recorren todos los elemento y se actualizan los pesos, previamente inicializados a 0, sumando la distancia del enemigo y restando la distancia al amigo. Posteriormente se normaliza el valor al rango [0,1]. 
funcion relief(conjunto\_entrenamiento) {
	pesos = Array.zeros(conjunto\_entrenamiento.longitudes)
	loop i in entrenamiento {
		amigo = conjunto\_entrenamiento[i].amigo() 
		enemigo = conjunto\_entrenamiento[i].enemigo() 
		pesos.actualizar(amigo, enemigo) 
	}
	pesos.normalizar() 
	devolver pesos
}

\pagebreak
\subsection{BL}
Para definir una busqueda local necesitamos generación de soluciones aleatorias, un operador de generación de vecinos y método de exploración del entorno. Queda aclarar que en la solución implementada no se genera el vecindario entero antes de realizar la búsqueda, sino se van generando vecinos de forma aleatoria hasta encontrar una mejoría. En el código fuente estas funciones no han sido implementadas por separado, sino todas juntas en en la función BL. 
funcion soluciones\_aleatorias(min=0, max=1, tamaño\_vector) { 
	devolver Aleatorio(min, max, tamaño\_vector) 
}
funcion generacion\_vecino(pesos\_inciales, desviacion\_standard, media, posicion) {
	devolver pesos\_inciales[posicion].variar(media, desviacion\_standard).truncar()
}
funcion exploracion\_entorno(conjunto\_entrenamiento) {
	pesos\_actuales = soluciones\_aleatorias(0,1,conjunto\_entrenamiento.longitudes)
	evaluacion\_actual = evaluarLeave1out(conjunto\_entrenamiento, pesos\_actuales)
	loop mientras mejorable y no\_lleva\_mucho\_ejecutando{
		vecino = generacion\_vecino(pesos\_actuales, 0.2, 0, Permutacion)
		evaluacion\_vecino = evaluarLeave1out(conjunto\_entrenamiento, vecino) 
		if evaluacion\_vecino > evaluacion\_actual {
			evaluacion\_actual = evaluacion\_vecino
			pesos\_actuales  = vecino 
		}
	}	 
} 
\subsection{Algoritmos genéticos estacionarios}
funcion estacionario(Poblacion matriz\_datos, funcion tipo\_cruce) devuelve un array de pesos:
    # Se ordena la población
    poblacion = ordenar(matriz\_datos, funcion\_evaluacion) 
	 repetir 15000 veces:
        # Competición entre 4 individuos
        seleccion = poblacion.elegir4individuos()
        c1, c2 = torneoTetra(seleccion)

        # Se hacen los cruces
        h1, h2 = tipo\_cruce(c1, c2)

        # Se aplican las mutaciones
        mutar(seleccion\_aleatoria(poblacion))
        h1.evaluacion = evaluar(h1)
        h2.evaluacion = evaluar(h2) 

        # Competición para entrar en la poblacion
        seleccion[0] = h1
        seleccion[1] = h2
        seleccion[2] = poblacion[0]
        seleccion[3] = poblacion[1]
        seleccion.ordenar()
        poblacion[0] = seleccion.mejor()
        poblacion[1] = seleccion.segundo\_mejor() 
        poblacion.ordenar() 

    devolver poblacion.mejor\_cromosoma()
\pagebreak
\subsection{}
\pagebreak
\subsection{}
\pagebreak
\subsection{}
\pagebreak
\subsection{}
\pagebreak
\subsection{}
\pagebreak

\section{Descripción en pseudocódigo de los algoritmos de comparación}

\pagebreak

\section{Procedimiento considerado para desarrollar la práctica}
Para esta práctica se ha decidido utilizar el lenguaje de programación Python por la velocidad de desarrollo y claridad del código. También se ha utilizado la librería numpy para la optimización de los calculos de los arrays. Como generación de numeros aleatorios se ha confiado en el módulo numpy.random y para medir el tiempo, la biblioteca time.  
\pagebreak
\subsection{Manual del usuario}
- Requisitos: Python3 y las librerías numpy, functools, arff, time
- Abrir el directorio donde se encuentra el archivo main.py en una terminal 
- Ejecutar python3 main.py 
- Esperar alrededor de 1 hora. Como indicación de progreso se puede leer de la salida standard los algoritmos ejecutados hasta el momento así como el que se está ejecutando actualmente. Hay 2 algoritmos, 3 bases de datos diferentes y 5 particiones de las bases de datos, por lo tanto hay 30 subapartados que deben ejecutarse en total. 
- Los resultados pueden leerse de la salida standard así como del fichero resultados.csv
\subsection{Mejoras realizadas respecto a la práctica 1}
La retroalimentación de la primera práctica ha sido muy útil para mejorar la presentación de esta segunda práctica. Las mejoras adoptadas han sido las siguientes:
- Los datos ahora se normalizan después de ser leidos y antes de ser procesados. En la práctica anterior por un descuido no fueron normalizados. 
- En la práctica anterior ya se utilizaba la biblioteca numpy, pero por debajo de la clase Elemento, que tenía un vector de características y la clase correspondiente. Para esta práctica, en lugar de una lista de variables Elemento se ha utilizado una matriz numpy y una lista paralela de clases.
- El leeme ha sido extendido para describir mejor el modo de ejecutar el programa
- Se ha añadido pseudocódigo de los operadores comunes 
\subsection{Mejoras pendientes para la siguiente práctica}
- Tiempo: A pesar de haber cambiado la estructura de datos, el programa sigue siendo lento. Para la siguiente práctica tengo planeado explorar diferentes métodos para mejorar esto como programación con hilos o semicompilación en c con librerías como weave. 
- Mejora de la P1: Comprobar por qué el algoritmo RELIEF me da un \% de reducción excesivo
- Memoria en LaTeX:  Para mejorar la presentación de la memoria y poder incluir fórmulas, índice generado automáticamente e imagenes incrustadas de manera más profesional planeo utilizar LaTeX en la última práctica. 

\section{Experimentos y análisis de los resultados}
\subsection{Casos del problema empleados y valores de los parámetros considerados}
Incluir semillas utilizzdas
Dado el tiempo necesario para ejecutar el programa (alrededor de 20 minutos), los pesos solo se han entrenado una vez con cada algoritmo y base de datos diferente, utilizando la semilla por defecto de la libería time. 

\subsection{Tablas de resultados obtenidos}
\pagebreak
\subsection{Análisis de resultados}
gráficas de convergencia, boxplots, análisis comparativo de las soluciones obtenidas, representación gráfica de las soluciones
\subsubsection{1-NN}
Este es el algoritmo base que hay que mejorar así que como era de esperar tiene las tasas de clasificación y reducción más bajas, aún así el tiempo de ejecución es casi despreciable. El porcentaje de clasificación es soprendentemente mejor para Spect-heart.
\subsubsection{Busqueda Local}
El porcentaje de clasificación tanto como el de reducción son los mejores en la mayor parte de los casos, descartando en Ozone, donde la reducción de RELIEF es mejor. 

\subsubsection{RELIEF}
Los resultados tienden a ser mejores que 1-NN pero inferiores a BL. En algunos casos puede presentar los mejores resultados, como en el porcentaje de clasificación de Ozone o el porcentaje de reducción de Spect-heart. El tiempo requerido también es varios ordenes de magnitud inferior al requerido por BL. 
\subsubsection{AGE-BLX}
El porcentaje de reducción, así como el porcentaje de clasificación son notablemente mejores que los de los algoritmos de la práctica anterior. Sin embargo, el tiempo en los algoritmos genéticos también avanza mucho. 
\subsubsection{AGE-CA}
El porcentaje de reducción es preocupantemente bajo en comparación con el algoritmo que utiliza BLX. Cabe preguntarse si eso es debido a algún error en la implementación del operador de cruce. El tiempo de ejecución también es muy alto en comparación a los algoritmos anteriores. 
\subsubsection{}
\subsubsection{}
\subsubsection{}
\subsubsection{}
\subsubsection{}
\subsubsection{Conclusión}
En la anterior práctica se concluía que no merecía la pena el tiempo de ejecución de BL y RELIEF, así como la complejidad de implementación, cuando utilizar unos pesos no ponderados no presenta unos resultados mucho peores. Sin embargo, en esta práctica se puede apreciar que la mejora en reducción y clasificación es muy buena en los algoritmos genéticos. 
\pagebreak
\section{Referencias bibliográficas}
\end{document}